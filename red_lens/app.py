# -*- coding: utf-8 -*-
"""
Streamlit Dashboard for RedLens
Interactive visualization and control panel
"""

import sys
from pathlib import Path

# Add parent directory to path
MEDIA_CRAWLER_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(MEDIA_CRAWLER_ROOT))

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime

from red_lens.db import BloggerDB, NoteDB, init_db
from red_lens.discovery import search_and_extract_users
from red_lens.pipeline import scrape_pending_bloggers
from red_lens.analyzer import (
    analyze_blogger,
    analyze_all_bloggers,
    download_outlier_covers,
    generate_ai_report
)


# Page configuration
st.set_page_config(
    page_title="RedLens - å°çº¢ä¹¦æ‘„å½±åšä¸»åˆ†æ",
    page_icon="ğŸ“¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize database
init_db()


def main():
    """Main Streamlit app"""

    # Title
    st.title("ğŸ“¸ RedLens - å°çº¢ä¹¦æ‘„å½±åšä¸»åˆ†æå·¥å…·")
    st.markdown("---")

    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ æ§åˆ¶é¢æ¿")

        # Section 1: Discovery
        st.subheader("ğŸ” åšä¸»å‘ç°")

        keywords_input = st.text_input(
            "æœç´¢å…³é”®è¯ (é€—å·åˆ†éš”)",
            value="å¯Œå£«æ‰«è¡—,äººåƒæ‘„å½±,èƒ¶ç‰‡è‰²è°ƒ",
            help="è¾“å…¥å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”"
        )

        min_likes = st.slider(
            "æœ€ä½ç‚¹èµæ•°è¿‡æ»¤",
            min_value=0,
            max_value=1000,
            value=200,
            step=50,
            help="ä»…ä¿ç•™ç¬”è®°ç‚¹èµæ•°è¶…è¿‡æ­¤å€¼çš„åšä¸»"
        )

        # Add mode selection
        run_mode = st.radio(
            "è¿è¡Œæ¨¡å¼",
            options=["ä½¿ç”¨ç°æœ‰æ•°æ®", "è¿è¡Œ MediaCrawler çˆ¬å–"],
            help="é€‰æ‹©æ˜¯ä½¿ç”¨å·²æœ‰JSONæ•°æ®è¿˜æ˜¯è¿è¡ŒMediaCrawlerè·å–æ–°æ•°æ®"
        )

        use_existing = (run_mode == "ä½¿ç”¨ç°æœ‰æ•°æ®")

        if st.button("ğŸš€ å¼€å§‹å‘ç°åšä¸»", type="primary", use_container_width=True):
            keywords = [k.strip() for k in keywords_input.split(",") if k.strip()]

            if not use_existing:
                st.warning("âš ï¸ å³å°†å¯åŠ¨ MediaCrawlerï¼Œéœ€è¦æµè§ˆå™¨äº¤äº’ï¼ˆç™»å½•ã€éªŒè¯ç­‰ï¼‰")
                st.info("è¯·åœ¨å¼¹å‡ºçš„æµè§ˆå™¨çª—å£ä¸­å®Œæˆç™»å½•æ­¥éª¤")

            with st.spinner("æ­£åœ¨æœç´¢åšä¸»..." if use_existing else "æ­£åœ¨è¿è¡Œ MediaCrawler..."):
                new_count = search_and_extract_users(
                    keywords,
                    min_likes=min_likes,
                    use_existing=use_existing
                )
                st.success(f"âœ“ å‘ç° {new_count} ä½æ–°åšä¸»!")
                st.rerun()

        st.markdown("---")

        # Section 2: Scraping
        st.subheader("ğŸ“¥ æ•°æ®é‡‡é›†")

        # Get all pending bloggers to extract unique keywords
        all_pending = BloggerDB.get_pending_bloggers(limit=1000)  # Get all pending
        pending_keywords = set()
        for blogger in all_pending:
            if blogger.get("source_keyword"):
                pending_keywords.add(blogger["source_keyword"])

        # Keyword filter
        keyword_filter_options = ["å…¨éƒ¨å…³é”®è¯"] + sorted(list(pending_keywords))
        selected_scrape_keyword = st.selectbox(
            "ç­›é€‰å¾…é‡‡é›†åšä¸»",
            options=keyword_filter_options,
            help="æŒ‰æ¥æºå…³é”®è¯ç­›é€‰è¦é‡‡é›†çš„åšä¸»"
        )

        # Count pending bloggers based on filter
        if selected_scrape_keyword == "å…¨éƒ¨å…³é”®è¯":
            pending_count = BloggerDB.count_by_status("pending")
            filter_keyword = None
        else:
            pending_count = BloggerDB.count_pending_by_keyword(selected_scrape_keyword)
            filter_keyword = selected_scrape_keyword

        st.info(f"å¾…é‡‡é›†åšä¸»: {pending_count} ä½")

        scrape_limit = st.number_input(
            "é‡‡é›†åšä¸»æ•°é‡",
            min_value=1,
            max_value=20,
            value=min(5, pending_count) if pending_count > 0 else 5,
            help="æ¯æ¬¡é‡‡é›†çš„åšä¸»æ•°é‡"
        )

        max_notes_per_blogger = st.slider(
            "æ¯ä¸ªåšä¸»çˆ¬å–ç¬”è®°æ•°é‡",
            min_value=10,
            max_value=200,
            value=100,
            step=10,
            help="æ¯ä¸ªåšä¸»æœ€å¤šçˆ¬å–çš„ç¬”è®°æ•°é‡ï¼ˆé»˜è®¤100æ¡ï¼‰"
        )

        if st.button("ğŸ“Š å¼€å§‹é‡‡é›†æ•°æ®", use_container_width=True):
            if pending_count == 0:
                st.warning("æ²¡æœ‰å¾…é‡‡é›†çš„åšä¸»")
            else:
                # Get filtered pending bloggers
                if filter_keyword:
                    target_bloggers = BloggerDB.get_pending_bloggers_by_keyword(
                        keyword=filter_keyword,
                        limit=scrape_limit
                    )
                else:
                    target_bloggers = BloggerDB.get_pending_bloggers(limit=scrape_limit)

                if not target_bloggers:
                    st.warning("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å¾…é‡‡é›†åšä¸»")
                else:
                    # Show which bloggers will be scraped
                    with st.expander("ğŸ“‹ å°†è¦é‡‡é›†çš„åšä¸»", expanded=False):
                        for blogger in target_bloggers:
                            st.markdown(f"- {blogger['nickname']} ({blogger.get('source_keyword', 'N/A')})")

                    with st.spinner(f"æ­£åœ¨é‡‡é›†æ•°æ®ï¼ˆæ¯ä½åšä¸»æœ€å¤š{max_notes_per_blogger}æ¡ç¬”è®°ï¼‰..."):
                        # Manually scrape the filtered bloggers
                        from red_lens.pipeline import run_mediacrawler_for_creator, load_notes_from_json
                        import time
                        import random

                        stats = {"scraped": 0, "failed": 0, "notes_added": 0}

                        for idx, blogger in enumerate(target_bloggers, 1):
                            user_id = blogger["user_id"]
                            nickname = blogger["nickname"]

                            st.text(f"[{idx}/{len(target_bloggers)}] æ­£åœ¨é‡‡é›†: {nickname}")

                            # Run MediaCrawler for this blogger
                            success = run_mediacrawler_for_creator(user_id, max_notes=max_notes_per_blogger)

                            if success:
                                # Load notes and save to database
                                json_dir = Path(__file__).parent.parent / "data" / "xhs" / "json"
                                creator_files = list(json_dir.glob("creator_contents_*.json"))

                                if creator_files:
                                    latest_file = max(creator_files, key=lambda p: p.stat().st_mtime)
                                    all_notes = load_notes_from_json(latest_file)
                                    user_notes = [n for n in all_notes if n["user_id"] == user_id]

                                    notes_added = 0
                                    for note in user_notes:
                                        try:
                                            NoteDB.insert_note(
                                                note_id=note["note_id"],
                                                user_id=note["user_id"],
                                                title=note["title"],
                                                desc=note["desc"],
                                                note_type=note["type"],
                                                likes=note["likes"],
                                                collects=note["collects"],
                                                comments=note["comments"],
                                                create_time=note["create_time"],
                                                cover_url=note["cover_url"],
                                                note_url=note.get("note_url", "")
                                            )
                                            notes_added += 1
                                        except Exception:
                                            pass

                                    BloggerDB.update_status(user_id, "scraped")
                                    stats["scraped"] += 1
                                    stats["notes_added"] += notes_added
                                else:
                                    BloggerDB.update_status(user_id, "error")
                                    stats["failed"] += 1
                            else:
                                BloggerDB.update_status(user_id, "error")
                                stats["failed"] += 1

                            # Delay between bloggers
                            if idx < len(target_bloggers):
                                time.sleep(random.randint(10, 30))

                        st.success(f"âœ“ é‡‡é›†å®Œæˆ! æˆåŠŸ: {stats['scraped']}, å¤±è´¥: {stats['failed']}, ç¬”è®°: {stats['notes_added']}")
                        st.rerun()

        st.markdown("---")

        # Section 3: Analysis
        st.subheader("ğŸ”¬ æ•°æ®åˆ†æ")

        if st.button("ğŸ”¥ è¯†åˆ«æ‰€æœ‰çˆ†æ¬¾", use_container_width=True):
            with st.spinner("æ­£åœ¨åˆ†æ..."):
                analyses = analyze_all_bloggers()
                st.success(f"âœ“ åˆ†æå®Œæˆ! å…±åˆ†æ {len(analyses)} ä½åšä¸»")
                st.rerun()

        if st.button("ğŸ“¥ ä¸‹è½½çˆ†æ¬¾å°é¢", use_container_width=True):
            with st.spinner("æ­£åœ¨ä¸‹è½½å°é¢å›¾..."):
                count = download_outlier_covers()
                st.success(f"âœ“ ä¸‹è½½å®Œæˆ! å…±ä¸‹è½½ {count} å¼ å°é¢")
                st.rerun()

        st.markdown("---")

        # Database stats
        st.subheader("ğŸ“ˆ æ•°æ®åº“ç»Ÿè®¡")
        total_bloggers = len(BloggerDB.get_all_bloggers())
        scraped_count = BloggerDB.count_by_status("scraped")
        error_count = BloggerDB.count_by_status("error")

        col1, col2 = st.columns(2)
        with col1:
            st.metric("æ€»åšä¸»", total_bloggers)
            st.metric("å·²é‡‡é›†", scraped_count)
        with col2:
            st.metric("å¾…é‡‡é›†", pending_count)
            st.metric("å¤±è´¥", error_count)

    # Main area
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š åšä¸»æ’è¡Œ", "ğŸ”¥ çˆ†æ¬¾ç”»å»Š", "ğŸ“ˆ è¯¦ç»†åˆ†æ", "ğŸ—‚ï¸ åšä¸»ç®¡ç†"])

    with tab1:
        show_blogger_ranking()

    with tab2:
        show_outlier_gallery()

    with tab3:
        show_detailed_analysis()

    with tab4:
        show_blogger_management()


def show_blogger_ranking():
    """Display blogger ranking"""
    st.header("ğŸ“Š åšä¸»æ’è¡Œæ¦œ")

    # Get all scraped bloggers
    scraped_bloggers = [b for b in BloggerDB.get_all_bloggers() if b["status"] == "scraped"]

    if not scraped_bloggers:
        st.info("æš‚æ— å·²é‡‡é›†çš„åšä¸»æ•°æ®ã€‚è¯·å…ˆä½¿ç”¨ä¾§è¾¹æ çš„ã€Œæ•°æ®é‡‡é›†ã€åŠŸèƒ½ã€‚")
        return

    # Analyze all bloggers
    analyses = []
    for blogger in scraped_bloggers:
        analysis = analyze_blogger(blogger["user_id"])
        if "error" not in analysis:
            analyses.append(analysis)

    if not analyses:
        st.warning("åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®")
        return

    # Sort by outlier rate
    analyses.sort(key=lambda x: (x["outlier_rate"], x["avg_likes"]), reverse=True)

    # Create DataFrame
    df_data = []
    for analysis in analyses:
        blogger = analysis["blogger"]
        df_data.append({
            "åšä¸»æ˜µç§°": blogger["nickname"],
            "æ€»ç¬”è®°æ•°": analysis["total_notes"],
            "å¹³å‡ç‚¹èµ": int(analysis["avg_likes"]),
            "çˆ†æ¬¾æ•°é‡": analysis["outlier_count"],
            "çˆ†æ¬¾ç‡": f"{analysis['outlier_rate']:.1%}",
            "æ€»äº’åŠ¨é‡": analysis["total_engagement"],
            "æ¥æºå…³é”®è¯": blogger["source_keyword"] or "N/A",
            "user_id": blogger["user_id"]  # Hidden column for selection
        })

    df = pd.DataFrame(df_data)

    # Display metrics
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("åšä¸»æ€»æ•°", len(analyses))
    with col2:
        total_notes = sum(a["total_notes"] for a in analyses)
        st.metric("æ€»ç¬”è®°æ•°", total_notes)
    with col3:
        total_outliers = sum(a["outlier_count"] for a in analyses)
        st.metric("æ€»çˆ†æ¬¾æ•°", total_outliers)
    with col4:
        avg_outlier_rate = sum(a["outlier_rate"] for a in analyses) / len(analyses)
        st.metric("å¹³å‡çˆ†æ¬¾ç‡", f"{avg_outlier_rate:.1%}")

    st.markdown("---")

    # Display table
    st.subheader("åšä¸»åˆ—è¡¨ (æŒ‰çˆ†æ¬¾ç‡æ’åº)")

    # Show dataframe without user_id column
    display_df = df.drop(columns=["user_id"])
    st.dataframe(
        display_df,
        use_container_width=True,
        height=400
    )

    # Visualization: Bar chart
    st.markdown("---")
    st.subheader("ğŸ“Š å¯è§†åŒ–åˆ†æ")

    col1, col2 = st.columns(2)

    with col1:
        # Outlier rate chart
        fig1 = px.bar(
            df.head(10),
            x="åšä¸»æ˜µç§°",
            y="çˆ†æ¬¾ç‡",
            title="Top 10 åšä¸»çˆ†æ¬¾ç‡",
            color="çˆ†æ¬¾ç‡",
            color_continuous_scale="Reds"
        )
        fig1.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig1, use_container_width=True)

    with col2:
        # Average likes chart
        fig2 = px.bar(
            df.head(10),
            x="åšä¸»æ˜µç§°",
            y="å¹³å‡ç‚¹èµ",
            title="Top 10 åšä¸»å¹³å‡ç‚¹èµæ•°",
            color="å¹³å‡ç‚¹èµ",
            color_continuous_scale="Blues"
        )
        fig2.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig2, use_container_width=True)

    # Scatter plot: Notes vs Outlier Rate
    fig3 = px.scatter(
        df,
        x="æ€»ç¬”è®°æ•°",
        y="çˆ†æ¬¾ç‡",
        size="å¹³å‡ç‚¹èµ",
        color="çˆ†æ¬¾æ•°é‡",
        hover_data=["åšä¸»æ˜µç§°"],
        title="ç¬”è®°æ•°é‡ vs çˆ†æ¬¾ç‡ (æ°”æ³¡å¤§å°=å¹³å‡ç‚¹èµ)",
        color_continuous_scale="Viridis"
    )
    st.plotly_chart(fig3, use_container_width=True)


def show_outlier_gallery():
    """Display outlier notes gallery"""
    st.header("ğŸ”¥ çˆ†æ¬¾å†…å®¹ç”»å»Š")

    # Get all outlier notes
    outlier_notes = NoteDB.get_outlier_notes()

    if not outlier_notes:
        st.info("æš‚æ— çˆ†æ¬¾å†…å®¹ã€‚è¯·å…ˆä½¿ç”¨ä¾§è¾¹æ çš„ã€Œæ•°æ®åˆ†æã€åŠŸèƒ½è¯†åˆ«çˆ†æ¬¾ã€‚")
        return

    # Sort by likes
    outlier_notes.sort(key=lambda x: x["likes"], reverse=True)

    st.success(f"å…±å‘ç° {len(outlier_notes)} ç¯‡çˆ†æ¬¾å†…å®¹")

    # Filter options
    col1, col2 = st.columns([1, 3])
    with col1:
        min_likes_filter = st.number_input("æœ€ä½ç‚¹èµæ•°", value=0, step=1000)
    with col2:
        # Get unique users
        users = list(set(note["user_id"] for note in outlier_notes))
        user_names = {}
        for user_id in users:
            blogger = BloggerDB.get_blogger(user_id)
            if blogger:
                user_names[user_id] = blogger["nickname"]

        selected_user = st.selectbox(
            "ç­›é€‰åšä¸»",
            options=["å…¨éƒ¨"] + list(user_names.values())
        )

    # Apply filters
    filtered_notes = outlier_notes
    if min_likes_filter > 0:
        filtered_notes = [n for n in filtered_notes if n["likes"] >= min_likes_filter]

    if selected_user != "å…¨éƒ¨":
        selected_user_id = [uid for uid, name in user_names.items() if name == selected_user][0]
        filtered_notes = [n for n in filtered_notes if n["user_id"] == selected_user_id]

    st.markdown(f"**ç­›é€‰å: {len(filtered_notes)} ç¯‡**")
    st.markdown("---")

    # Display in grid
    cols_per_row = 3
    for i in range(0, len(filtered_notes), cols_per_row):
        cols = st.columns(cols_per_row)

        for j, col in enumerate(cols):
            idx = i + j
            if idx >= len(filtered_notes):
                break

            note = filtered_notes[idx]
            blogger = BloggerDB.get_blogger(note["user_id"])
            blogger_name = blogger["nickname"] if blogger else "Unknown"

            with col:
                # Card container
                with st.container():
                    st.markdown(f"### {note['title'][:30]}...")

                    # Display image if available
                    if note["local_cover_path"]:
                        try:
                            st.image(note["local_cover_path"], use_container_width=True)
                        except:
                            st.info("å°é¢å›¾åŠ è½½å¤±è´¥")
                    elif note["cover_url"]:
                        st.info("å°é¢æœªä¸‹è½½")
                    else:
                        st.info("æ— å°é¢å›¾")

                    # Metrics
                    metric_col1, metric_col2, metric_col3 = st.columns(3)
                    with metric_col1:
                        st.metric("â¤ï¸ ç‚¹èµ", f"{note['likes']:,}")
                    with metric_col2:
                        st.metric("â­ æ”¶è—", f"{note['collects']:,}")
                    with metric_col3:
                        st.metric("ğŸ’¬ è¯„è®º", f"{note['comments']:,}")

                    # Author and type
                    st.caption(f"ğŸ‘¤ {blogger_name}")
                    st.caption(f"ğŸ“ {note['type']} | ğŸ• {note['create_time']}")

                    # Link
                    if note.get("note_url"):
                        st.link_button("æŸ¥çœ‹åŸæ–‡", note["note_url"], use_container_width=True)

                st.markdown("---")


def show_detailed_analysis():
    """Display detailed analysis for selected blogger"""
    st.header("ğŸ“ˆ åšä¸»è¯¦ç»†åˆ†æ")

    # Get all scraped bloggers
    scraped_bloggers = [b for b in BloggerDB.get_all_bloggers() if b["status"] == "scraped"]

    if not scraped_bloggers:
        st.info("æš‚æ— å·²é‡‡é›†çš„åšä¸»æ•°æ®ã€‚")
        return

    # Blogger selection
    blogger_names = {b["user_id"]: b["nickname"] for b in scraped_bloggers}
    selected_name = st.selectbox(
        "é€‰æ‹©åšä¸»",
        options=list(blogger_names.values())
    )

    # Find user_id
    selected_user_id = [uid for uid, name in blogger_names.items() if name == selected_name][0]

    # Analyze
    analysis = analyze_blogger(selected_user_id)

    if "error" in analysis:
        st.error(f"åˆ†æå¤±è´¥: {analysis['error']}")
        return

    blogger = analysis["blogger"]

    # Display header
    col1, col2, col3 = st.columns([1, 3, 1])
    with col1:
        if blogger["avatar_url"]:
            st.image(blogger["avatar_url"], width=150)
        else:
            st.info("æ— å¤´åƒ")
    with col2:
        st.subheader(blogger["nickname"])
        st.caption(f"User ID: {blogger['user_id']}")
        st.caption(f"çŠ¶æ€: {blogger['status']} | æ¥æº: {blogger['source_keyword']}")
    with col3:
        st.markdown("###  ")  # Spacing
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ•°æ®", key=f"reset_{selected_user_id}", type="secondary", use_container_width=True):
            st.session_state[f"show_confirm_reset_{selected_user_id}"] = True

    # Confirmation dialog for reset
    if st.session_state.get(f"show_confirm_reset_{selected_user_id}", False):
        with st.expander("âš ï¸ ç¡®è®¤æ¸…ç©ºæ•°æ®", expanded=True):
            st.warning(f"ç¡®è®¤è¦æ¸…ç©º **{blogger['nickname']}** çš„æ‰€æœ‰ç¬”è®°æ•°æ®å—ï¼Ÿ")
            st.info("åšä¸»çŠ¶æ€å°†é‡ç½®ä¸º pendingï¼Œæ‰€æœ‰ç¬”è®°å°†è¢«åˆ é™¤ã€‚æ­¤æ“ä½œä¸å¯æ¢å¤ï¼")

            col_a, col_b = st.columns(2)
            with col_a:
                if st.button("âœ… ç¡®è®¤æ¸…ç©º", key=f"confirm_yes_{selected_user_id}", type="primary", use_container_width=True):
                    success = BloggerDB.reset_blogger_status(selected_user_id)
                    if success:
                        st.success(f"âœ“ å·²æ¸…ç©º {blogger['nickname']} çš„æ‰€æœ‰ç¬”è®°æ•°æ®")
                        st.session_state[f"show_confirm_reset_{selected_user_id}"] = False
                        st.rerun()
                    else:
                        st.error("æ¸…ç©ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“")
            with col_b:
                if st.button("âŒ å–æ¶ˆ", key=f"confirm_no_{selected_user_id}", use_container_width=True):
                    st.session_state[f"show_confirm_reset_{selected_user_id}"] = False
                    st.rerun()

    st.markdown("---")

    # Metrics
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»ç¬”è®°æ•°", analysis["total_notes"])
    with col2:
        st.metric("å¹³å‡ç‚¹èµ", f"{analysis['avg_likes']:.0f}")
    with col3:
        st.metric("çˆ†æ¬¾æ•°é‡", analysis["outlier_count"])
    with col4:
        st.metric("çˆ†æ¬¾ç‡", f"{analysis['outlier_rate']:.1%}")

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»ç‚¹èµ", f"{analysis['total_likes']:,}")
    with col2:
        st.metric("æ€»æ”¶è—", f"{analysis['total_collects']:,}")
    with col3:
        st.metric("æ€»è¯„è®º", f"{analysis['total_comments']:,}")
    with col4:
        st.metric("å¹³å‡äº’åŠ¨", f"{analysis['avg_engagement']:.0f}")

    st.markdown("---")

    # Content distribution
    st.subheader("ğŸ“Š å†…å®¹åˆ†å¸ƒ")
    col1, col2 = st.columns(2)

    with col1:
        # Pie chart: Content type
        fig_pie = go.Figure(data=[go.Pie(
            labels=["å›¾æ–‡", "è§†é¢‘"],
            values=[analysis["image_count"], analysis["video_count"]],
            hole=0.3
        )])
        fig_pie.update_layout(title="å†…å®¹ç±»å‹åˆ†å¸ƒ")
        st.plotly_chart(fig_pie, use_container_width=True)

    with col2:
        # Bar chart: Outlier vs Normal
        fig_bar = go.Figure(data=[go.Bar(
            x=["æ™®é€šå†…å®¹", "çˆ†æ¬¾å†…å®¹"],
            y=[analysis["total_notes"] - analysis["outlier_count"], analysis["outlier_count"]],
            marker_color=["lightblue", "red"]
        )])
        fig_bar.update_layout(title="å†…å®¹è´¨é‡åˆ†å¸ƒ", yaxis_title="æ•°é‡")
        st.plotly_chart(fig_bar, use_container_width=True)

    # Notes timeline
    st.subheader("ğŸ“ˆ ç¬”è®°æ•°æ®è¶‹åŠ¿")

    notes = NoteDB.get_notes_by_user(selected_user_id)
    if notes:
        df_notes = pd.DataFrame(notes)

        # Line chart: Likes over time
        fig_line = px.line(
            df_notes,
            x="create_time",
            y="likes",
            title="ç‚¹èµæ•°æ—¶é—´è¶‹åŠ¿",
            markers=True
        )
        fig_line.update_traces(line_color="red")
        st.plotly_chart(fig_line, use_container_width=True)

    # AI Report
    st.markdown("---")
    st.subheader("ğŸ¤– AI æ´å¯ŸæŠ¥å‘Š")

    if st.button("ç”Ÿæˆ AI æŠ¥å‘Š", type="primary"):
        with st.spinner("AI æ­£åœ¨åˆ†æ..."):
            report = generate_ai_report(selected_user_id, use_mock=True)
            st.markdown(report)

    # Top notes
    st.markdown("---")
    st.subheader("ğŸ” çƒ­é—¨ç¬”è®° Top 10")

    if notes:
        top_notes = sorted(notes, key=lambda x: x["likes"], reverse=True)[:10]

        for idx, note in enumerate(top_notes, 1):
            with st.container():
                # Create a card-like display for each note
                col1, col2, col3, col4, col5 = st.columns([3, 1, 1, 1, 1])

                with col1:
                    outlier_badge = "ğŸ”¥ " if note["is_outlier"] else ""
                    st.markdown(f"**{idx}. {outlier_badge}{note['title'][:50]}...**")
                    st.caption(f"ğŸ“ {note['type']} | ğŸ• {note['create_time']}")

                with col2:
                    st.metric("â¤ï¸", f"{note['likes']:,}")

                with col3:
                    st.metric("â­", f"{note['collects']:,}")

                with col4:
                    st.metric("ğŸ’¬", f"{note['comments']:,}")

                with col5:
                    if note.get("note_url"):
                        st.link_button("æŸ¥çœ‹", note["note_url"], use_container_width=True)
                    else:
                        st.caption("æ— é“¾æ¥")

                st.markdown("---")


def show_blogger_management():
    """Display blogger management page with filtering and batch operations"""
    st.header("ğŸ—‚ï¸ åšä¸»ç®¡ç†")

    # Get all bloggers
    all_bloggers = BloggerDB.get_all_bloggers()

    if not all_bloggers:
        st.info("æš‚æ— åšä¸»æ•°æ®")
        return

    st.success(f"æ•°æ®åº“ä¸­å…±æœ‰ {len(all_bloggers)} ä½åšä¸»")

    # Filters
    st.subheader("ğŸ” ç­›é€‰æ¡ä»¶")
    col1, col2 = st.columns(2)

    with col1:
        # Status filter
        status_options = ["å…¨éƒ¨çŠ¶æ€", "pending", "scraped", "error"]
        selected_status = st.selectbox("æŒ‰çŠ¶æ€ç­›é€‰", status_options)

    with col2:
        # Keyword filter
        # Get unique keywords
        keywords = set()
        for blogger in all_bloggers:
            if blogger.get("source_keyword"):
                keywords.add(blogger["source_keyword"])

        keyword_options = ["å…¨éƒ¨å…³é”®è¯"] + sorted(list(keywords))
        selected_keyword = st.selectbox("æŒ‰æ¥æºå…³é”®è¯ç­›é€‰", keyword_options)

    # Apply filters
    filtered_bloggers = all_bloggers

    if selected_status != "å…¨éƒ¨çŠ¶æ€":
        filtered_bloggers = [b for b in filtered_bloggers if b["status"] == selected_status]

    if selected_keyword != "å…¨éƒ¨å…³é”®è¯":
        filtered_bloggers = [b for b in filtered_bloggers if b.get("source_keyword") == selected_keyword]

    st.info(f"ç­›é€‰å: {len(filtered_bloggers)} ä½åšä¸»")

    st.markdown("---")

    # Blogger list with checkboxes
    st.subheader("ğŸ“‹ åšä¸»åˆ—è¡¨")

    if not filtered_bloggers:
        st.warning("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„åšä¸»")
        return

    # Select all checkbox
    select_all = st.checkbox("å…¨é€‰", key="select_all_bloggers")

    # Initialize session state for selections
    if "selected_bloggers" not in st.session_state:
        st.session_state.selected_bloggers = set()

    if select_all:
        st.session_state.selected_bloggers = set(b["user_id"] for b in filtered_bloggers)
    elif not select_all and len(st.session_state.selected_bloggers) == len(filtered_bloggers):
        # If all were selected and user unchecks "select all"
        st.session_state.selected_bloggers = set()

    # Display bloggers in a scrollable container
    st.markdown("**é€‰æ‹©è¦åˆ é™¤çš„åšä¸»ï¼š**")

    # Create a table-like display with checkboxes
    for idx, blogger in enumerate(filtered_bloggers):
        col1, col2, col3, col4, col5 = st.columns([0.5, 2, 1.5, 1, 1])

        with col1:
            is_selected = blogger["user_id"] in st.session_state.selected_bloggers
            if st.checkbox("", value=is_selected, key=f"cb_{blogger['user_id']}_{idx}"):
                st.session_state.selected_bloggers.add(blogger["user_id"])
            else:
                st.session_state.selected_bloggers.discard(blogger["user_id"])

        with col2:
            st.markdown(f"**{blogger['nickname']}**")

        with col3:
            st.caption(f"å…³é”®è¯: {blogger.get('source_keyword', 'N/A')}")

        with col4:
            status_emoji = {"pending": "â³", "scraped": "âœ…", "error": "âŒ"}
            st.caption(f"{status_emoji.get(blogger['status'], 'â“')} {blogger['status']}")

        with col5:
            # Get note count
            note_count = NoteDB.count_notes_by_user(blogger["user_id"])
            st.caption(f"ğŸ“ {note_count} ç¬”è®°")

    st.markdown("---")

    # Batch operations
    st.subheader("âš™ï¸ æ‰¹é‡æ“ä½œ")

    selected_count = len(st.session_state.selected_bloggers)
    st.info(f"å·²é€‰æ‹© {selected_count} ä½åšä¸»")

    if selected_count == 0:
        st.warning("è¯·å…ˆé€‰æ‹©è¦æ“ä½œçš„åšä¸»")
    else:
        col1, col2 = st.columns(2)

        with col1:
            if st.button("ğŸ—‘ï¸ æ‰¹é‡åˆ é™¤é€‰ä¸­åšä¸»", type="primary", use_container_width=True):
                st.session_state.show_batch_delete_confirm = True

        with col2:
            if st.button("ğŸ”„ æ‰¹é‡é‡ç½®ä¸º pending", use_container_width=True):
                st.session_state.show_batch_reset_confirm = True

    # Batch delete confirmation
    if st.session_state.get("show_batch_delete_confirm", False):
        with st.expander("âš ï¸ ç¡®è®¤æ‰¹é‡åˆ é™¤", expanded=True):
            st.error(f"ç¡®è®¤è¦åˆ é™¤é€‰ä¸­çš„ **{selected_count}** ä½åšä¸»åŠå…¶æ‰€æœ‰ç¬”è®°å—ï¼Ÿ")
            st.warning("æ­¤æ“ä½œå°†æ°¸ä¹…åˆ é™¤åšä¸»ä¿¡æ¯å’Œæ‰€æœ‰ç¬”è®°ï¼Œä¸å¯æ¢å¤ï¼")

            # Show list of bloggers to be deleted
            st.markdown("**å°†è¦åˆ é™¤çš„åšä¸»ï¼š**")
            for user_id in list(st.session_state.selected_bloggers)[:10]:  # Show first 10
                blogger = next((b for b in filtered_bloggers if b["user_id"] == user_id), None)
                if blogger:
                    st.markdown(f"- {blogger['nickname']} ({blogger.get('source_keyword', 'N/A')})")
            if selected_count > 10:
                st.markdown(f"... ä»¥åŠå…¶ä»– {selected_count - 10} ä½åšä¸»")

            col_a, col_b = st.columns(2)
            with col_a:
                if st.button("âœ… ç¡®è®¤åˆ é™¤", key="confirm_batch_delete", type="primary", use_container_width=True):
                    deleted_count = 0
                    total_notes_deleted = 0

                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    for i, user_id in enumerate(st.session_state.selected_bloggers):
                        status_text.text(f"æ­£åœ¨åˆ é™¤... ({i+1}/{selected_count})")
                        progress_bar.progress((i + 1) / selected_count)

                        # Count notes before deletion
                        note_count = NoteDB.count_notes_by_user(user_id)

                        # Delete blogger and notes
                        if BloggerDB.delete_blogger(user_id):
                            deleted_count += 1
                            total_notes_deleted += note_count

                    st.success(f"âœ“ å·²åˆ é™¤ {deleted_count} ä½åšä¸»å’Œ {total_notes_deleted} æ¡ç¬”è®°")
                    st.session_state.selected_bloggers = set()
                    st.session_state.show_batch_delete_confirm = False
                    st.rerun()

            with col_b:
                if st.button("âŒ å–æ¶ˆ", key="cancel_batch_delete", use_container_width=True):
                    st.session_state.show_batch_delete_confirm = False
                    st.rerun()

    # Batch reset confirmation
    if st.session_state.get("show_batch_reset_confirm", False):
        with st.expander("âš ï¸ ç¡®è®¤æ‰¹é‡é‡ç½®", expanded=True):
            st.warning(f"ç¡®è®¤è¦å°†é€‰ä¸­çš„ **{selected_count}** ä½åšä¸»é‡ç½®ä¸º pending çŠ¶æ€å—ï¼Ÿ")
            st.info("æ­¤æ“ä½œå°†åˆ é™¤è¿™äº›åšä¸»çš„æ‰€æœ‰ç¬”è®°ï¼Œä½†ä¿ç•™åšä¸»ä¿¡æ¯ã€‚")

            col_a, col_b = st.columns(2)
            with col_a:
                if st.button("âœ… ç¡®è®¤é‡ç½®", key="confirm_batch_reset", type="primary", use_container_width=True):
                    reset_count = 0
                    total_notes_deleted = 0

                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    for i, user_id in enumerate(st.session_state.selected_bloggers):
                        status_text.text(f"æ­£åœ¨é‡ç½®... ({i+1}/{selected_count})")
                        progress_bar.progress((i + 1) / selected_count)

                        # Count notes before deletion
                        note_count = NoteDB.count_notes_by_user(user_id)

                        # Reset blogger status
                        if BloggerDB.reset_blogger_status(user_id):
                            reset_count += 1
                            total_notes_deleted += note_count

                    st.success(f"âœ“ å·²é‡ç½® {reset_count} ä½åšä¸»ï¼Œåˆ é™¤ {total_notes_deleted} æ¡ç¬”è®°")
                    st.session_state.selected_bloggers = set()
                    st.session_state.show_batch_reset_confirm = False
                    st.rerun()

            with col_b:
                if st.button("âŒ å–æ¶ˆ", key="cancel_batch_reset", use_container_width=True):
                    st.session_state.show_batch_reset_confirm = False
                    st.rerun()


if __name__ == "__main__":
    main()
