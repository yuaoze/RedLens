# -*- coding: utf-8 -*-
"""
Streamlit Dashboard for RedLens
Interactive visualization and control panel
"""

import sys
from pathlib import Path

# Add parent directory to path
MEDIA_CRAWLER_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(MEDIA_CRAWLER_ROOT))

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime

from red_lens.db import BloggerDB, NoteDB, init_db
from red_lens.discovery import search_and_extract_users
from red_lens.pipeline import scrape_pending_bloggers
from red_lens.analyzer import (
    analyze_blogger,
    analyze_all_bloggers,
    download_outlier_covers,
    generate_ai_report
)


# Page configuration
st.set_page_config(
    page_title="RedLens - å°çº¢ä¹¦æ‘„å½±åšä¸»åˆ†æ",
    page_icon="ğŸ“¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize database
init_db()


def main():
    """Main Streamlit app"""

    # Title
    st.title("ğŸ“¸ RedLens - å°çº¢ä¹¦æ‘„å½±åšä¸»åˆ†æå·¥å…·")
    st.markdown("---")

    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ æ§åˆ¶é¢æ¿")

        # Section 1: Discovery
        st.subheader("ğŸ” åšä¸»å‘ç°")

        keywords_input = st.text_input(
            "æœç´¢å…³é”®è¯ (é€—å·åˆ†éš”)",
            value="å¯Œå£«æ‰«è¡—,äººåƒæ‘„å½±,èƒ¶ç‰‡è‰²è°ƒ",
            help="è¾“å…¥å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”"
        )

        min_likes = st.slider(
            "æœ€ä½ç‚¹èµæ•°è¿‡æ»¤",
            min_value=0,
            max_value=1000,
            value=200,
            step=50,
            help="ä»…ä¿ç•™ç¬”è®°ç‚¹èµæ•°è¶…è¿‡æ­¤å€¼çš„åšä¸»"
        )

        # Add mode selection
        run_mode = st.radio(
            "è¿è¡Œæ¨¡å¼",
            options=["ä½¿ç”¨ç°æœ‰æ•°æ®", "è¿è¡Œ MediaCrawler çˆ¬å–"],
            help="é€‰æ‹©æ˜¯ä½¿ç”¨å·²æœ‰JSONæ•°æ®è¿˜æ˜¯è¿è¡ŒMediaCrawlerè·å–æ–°æ•°æ®"
        )

        use_existing = (run_mode == "ä½¿ç”¨ç°æœ‰æ•°æ®")

        if st.button("ğŸš€ å¼€å§‹å‘ç°åšä¸»", type="primary", use_container_width=True):
            keywords = [k.strip() for k in keywords_input.split(",") if k.strip()]

            if not use_existing:
                st.warning("âš ï¸ å³å°†å¯åŠ¨ MediaCrawlerï¼Œéœ€è¦æµè§ˆå™¨äº¤äº’ï¼ˆç™»å½•ã€éªŒè¯ç­‰ï¼‰")
                st.info("è¯·åœ¨å¼¹å‡ºçš„æµè§ˆå™¨çª—å£ä¸­å®Œæˆç™»å½•æ­¥éª¤")

            with st.spinner("æ­£åœ¨æœç´¢åšä¸»..." if use_existing else "æ­£åœ¨è¿è¡Œ MediaCrawler..."):
                new_count = search_and_extract_users(
                    keywords,
                    min_likes=min_likes,
                    use_existing=use_existing
                )
                st.success(f"âœ“ å‘ç° {new_count} ä½æ–°åšä¸»!")
                st.rerun()

        st.markdown("---")

        # Section 2: Scraping
        st.subheader("ğŸ“¥ æ•°æ®é‡‡é›†")

        # Check for resumable bloggers
        resumable_count = BloggerDB.count_resumable_bloggers()
        pending_count = BloggerDB.count_by_status("pending")

        # Display status
        col_status1, col_status2 = st.columns(2)
        with col_status1:
            st.metric("å¾…é‡‡é›†åšä¸»", pending_count)
        with col_status2:
            st.metric("å¯æ¢å¤é‡‡é›†", resumable_count)

        # Mode selection
        collection_mode = st.radio(
            "é‡‡é›†æ¨¡å¼",
            options=["æ­£å¸¸é‡‡é›†", "æ¢å¤é‡‡é›†"],
            help="æ­£å¸¸é‡‡é›†ï¼šé‡‡é›†æ–°çš„å¾…å¤„ç†åšä¸»ï½œæ¢å¤é‡‡é›†ï¼šç»§ç»­æœªå®Œæˆçš„é‡‡é›†ä»»åŠ¡",
            horizontal=True
        )

        st.markdown("---")

        # Mode 1: Normal Collection
        if collection_mode == "æ­£å¸¸é‡‡é›†":
            st.subheader("ğŸ“Š æ­£å¸¸é‡‡é›†æ¨¡å¼")

            if pending_count == 0:
                st.warning("æ²¡æœ‰å¾…é‡‡é›†çš„åšä¸»")
            else:
                # Get all pending bloggers to extract unique keywords
                all_pending = BloggerDB.get_pending_bloggers(limit=1000)
                pending_keywords = set()
                for blogger in all_pending:
                    if blogger.get("source_keyword"):
                        pending_keywords.add(blogger["source_keyword"])

                # Keyword filter
                keyword_filter_options = ["å…¨éƒ¨å…³é”®è¯"] + sorted(list(pending_keywords))
                selected_scrape_keyword = st.selectbox(
                    "ç­›é€‰å¾…é‡‡é›†åšä¸»",
                    options=keyword_filter_options,
                    help="æŒ‰æ¥æºå…³é”®è¯ç­›é€‰è¦é‡‡é›†çš„åšä¸»"
                )

                # Count pending bloggers based on filter
                if selected_scrape_keyword == "å…¨éƒ¨å…³é”®è¯":
                    filtered_pending_count = pending_count
                    filter_keyword = None
                else:
                    filtered_pending_count = BloggerDB.count_pending_by_keyword(selected_scrape_keyword)
                    filter_keyword = selected_scrape_keyword

                st.info(f"ç¬¦åˆæ¡ä»¶çš„å¾…é‡‡é›†åšä¸»: {filtered_pending_count} ä½")

                scrape_limit = st.number_input(
                    "é‡‡é›†åšä¸»æ•°é‡",
                    min_value=1,
                    max_value=20,
                    value=min(5, filtered_pending_count) if filtered_pending_count > 0 else 5,
                    help="æ¯æ¬¡é‡‡é›†çš„åšä¸»æ•°é‡"
                )

                max_notes_per_blogger = st.slider(
                    "æ¯ä¸ªåšä¸»çˆ¬å–ç¬”è®°æ•°é‡",
                    min_value=10,
                    max_value=200,
                    value=100,
                    step=10,
                    help="æ¯ä¸ªåšä¸»æœ€å¤šçˆ¬å–çš„ç¬”è®°æ•°é‡ï¼ˆé»˜è®¤100æ¡ï¼‰"
                )

                # Advanced settings
                with st.expander("âš™ï¸ é«˜çº§è®¾ç½®", expanded=False):
                    # Fans filter
                    enable_fans_filter = st.checkbox(
                        "å¯ç”¨ç²‰ä¸æ•°è¿‡æ»¤",
                        value=False,
                        help="é‡‡é›†å‰æ£€æŸ¥åšä¸»ç²‰ä¸æ•°ï¼Œè·³è¿‡ç²‰ä¸æ•°ä½äºé˜ˆå€¼çš„åšä¸»"
                    )

                    min_fans = 0
                    if enable_fans_filter:
                        min_fans = st.number_input(
                            "æœ€ä½ç²‰ä¸æ•°é˜ˆå€¼",
                            min_value=0,
                            max_value=1000000,
                            value=1000,
                            step=1000,
                            help="ç²‰ä¸æ•°ä½äºæ­¤å€¼çš„åšä¸»å°†è¢«è·³è¿‡ï¼Œä¸é‡‡é›†å…¶ç¬”è®°"
                        )

                    st.markdown("---")

                    # Batch size
                    batch_size = st.number_input(
                        "æ‰¹é‡å¤§å°",
                        min_value=1,
                        max_value=20,
                        value=5,
                        step=1,
                        help="æ¯æ‰¹å¤„ç†çš„åšä¸»æ•°é‡ã€‚æ•°é‡è¶Šå°è¶Šç¨³å®šï¼Œä½†æ€»è€—æ—¶è¶Šé•¿ã€‚æ¨è5ä¸ªã€‚"
                    )
                    st.caption("ğŸ’¡ æ‰¹é‡å¤„ç†è¯´æ˜ï¼š")
                    st.caption("- åšä¸»æ•°é‡ â‰¤ æ‰¹é‡å¤§å°ï¼šä¸€æ¬¡æ€§å¤„ç†")
                    st.caption("- åšä¸»æ•°é‡ > æ‰¹é‡å¤§å°ï¼šè‡ªåŠ¨åˆ†æ‰¹å¤„ç†")
                    st.caption("- é¢„è®¡æ—¶é—´ â‰ˆ æ‰¹æ¬¡æ•° Ã— (æ‰¹é‡å¤§å° Ã— ç¬”è®°æ•° Ã— 4ç§’)")

                if st.button("ğŸ“Š å¼€å§‹æ­£å¸¸é‡‡é›†", type="primary", use_container_width=True):
                    if filtered_pending_count == 0:
                        st.warning("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å¾…é‡‡é›†åšä¸»")
                    else:
                        # Normal collection - no resume
                        with st.spinner(f"æ­£åœ¨é‡‡é›†æ•°æ®ï¼ˆæ¯ä½åšä¸»æœ€å¤š{max_notes_per_blogger}æ¡ç¬”è®°ï¼‰..."):
                            stats = scrape_pending_bloggers(
                                limit=scrape_limit,
                                use_existing_data=False,
                                max_notes=max_notes_per_blogger,
                                min_fans=min_fans,
                                resume_partial=False,  # Disable resume in normal mode
                                batch_size=batch_size
                            )

                            msg = f"âœ“ é‡‡é›†å®Œæˆ! æˆåŠŸ: {stats['scraped']}, å¤±è´¥: {stats['failed']}, ç¬”è®°: {stats['notes_added']}"
                            if stats.get('resumed', 0) > 0:
                                msg += f", æ¢å¤: {stats['resumed']}"
                            if stats['skipped_low_fans'] > 0:
                                msg += f", ç²‰ä¸æ•°ä¸è¶³è·³è¿‡: {stats['skipped_low_fans']}"
                            st.success(msg)
                            st.rerun()

        # Mode 2: Resume Collection
        else:
            st.subheader("ğŸ”„ æ¢å¤é‡‡é›†æ¨¡å¼")

            if resumable_count == 0:
                st.warning("æ²¡æœ‰å¯æ¢å¤çš„é‡‡é›†ä»»åŠ¡")
                st.info("ğŸ’¡ æç¤ºï¼šåœ¨æ­£å¸¸é‡‡é›†è¿‡ç¨‹ä¸­ä¸­æ–­åï¼Œåšä¸»ä¼šè¿›å…¥å¯æ¢å¤çŠ¶æ€")
            else:
                # Get resumable bloggers
                resumable_bloggers = BloggerDB.get_resumable_bloggers()

                # Create blogger selection options
                blogger_options = {}
                for blogger in resumable_bloggers:
                    progress = BloggerDB.get_scrape_progress(blogger['user_id'])
                    label = f"{blogger['nickname']} ({progress['notes_collected']}/{progress['notes_target']} ç¬”è®°)"
                    blogger_options[label] = blogger['user_id']

                # Multi-select for bloggers to resume
                st.write("é€‰æ‹©è¦æ¢å¤é‡‡é›†çš„åšä¸»ï¼š")
                selected_bloggers = st.multiselect(
                    "é€‰æ‹©åšä¸»",
                    options=list(blogger_options.keys()),
                    default=list(blogger_options.keys())[:min(3, len(blogger_options))],  # Default select first 3
                    help="å¯ä»¥é€‰æ‹©å¤šä¸ªåšä¸»åŒæ—¶æ¢å¤é‡‡é›†"
                )

                if selected_bloggers:
                    selected_user_ids = [blogger_options[label] for label in selected_bloggers]

                    # Show selected bloggers with progress
                    st.write(f"å·²é€‰æ‹© {len(selected_user_ids)} ä½åšä¸»ï¼š")
                    for label in selected_bloggers:
                        st.caption(f"  â€¢ {label}")

                    max_notes_per_blogger = st.slider(
                        "æ¯ä¸ªåšä¸»ç¬”è®°ç›®æ ‡æ•°é‡",
                        min_value=10,
                        max_value=200,
                        value=100,
                        step=10,
                        help="æ¯ä¸ªåšä¸»çš„ç›®æ ‡ç¬”è®°æ•°é‡ï¼ˆä¼šç»§ç»­é‡‡é›†åˆ°è¾¾æ­¤æ•°é‡ï¼‰"
                    )

                    # Advanced settings for resume mode
                    with st.expander("âš™ï¸ é«˜çº§è®¾ç½®", expanded=False):
                        # Batch size
                        batch_size = st.number_input(
                            "æ‰¹é‡å¤§å°",
                            min_value=1,
                            max_value=20,
                            value=5,
                            step=1,
                            help="æ¯æ‰¹å¤„ç†çš„åšä¸»æ•°é‡"
                        )

                    if st.button("ğŸ”„ å¼€å§‹æ¢å¤é‡‡é›†", type="primary", use_container_width=True):
                        # Resume collection for selected bloggers using smart filtering
                        with st.spinner(f"æ­£åœ¨æ¢å¤é‡‡é›† {len(selected_user_ids)} ä½åšä¸»çš„æ•°æ®..."):
                            # Import the new function for resume mode
                            from red_lens.pipeline import scrape_specific_bloggers

                            # Use the new function with smart filtering (excludes already collected notes)
                            stats = scrape_specific_bloggers(
                                user_ids=selected_user_ids,
                                max_notes=max_notes_per_blogger,
                                batch_size=batch_size
                            )

                            msg = f"âœ“ æ¢å¤é‡‡é›†å®Œæˆ! å·²æ¢å¤: {stats['resumed']}, æˆåŠŸ: {stats['scraped']}, å¤±è´¥: {stats['failed']}, æ–°å¢ç¬”è®°: {stats['notes_added']}"
                            st.success(msg)
                            st.rerun()
                else:
                    st.info("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªåšä¸»è¿›è¡Œæ¢å¤é‡‡é›†")

        st.markdown("---")

        # Section 3: Analysis
        st.subheader("ğŸ”¬ æ•°æ®åˆ†æ")

        if st.button("ğŸ”¥ è¯†åˆ«æ‰€æœ‰çˆ†æ¬¾", use_container_width=True):
            with st.spinner("æ­£åœ¨åˆ†æ..."):
                analyses = analyze_all_bloggers()
                st.success(f"âœ“ åˆ†æå®Œæˆ! å…±åˆ†æ {len(analyses)} ä½åšä¸»")
                st.rerun()

        if st.button("ğŸ“¥ ä¸‹è½½çˆ†æ¬¾å°é¢", use_container_width=True):
            with st.spinner("æ­£åœ¨ä¸‹è½½å°é¢å›¾..."):
                count = download_outlier_covers()
                st.success(f"âœ“ ä¸‹è½½å®Œæˆ! å…±ä¸‹è½½ {count} å¼ å°é¢")
                st.rerun()

        st.markdown("---")

        # Database stats
        st.subheader("ğŸ“ˆ æ•°æ®åº“ç»Ÿè®¡")
        total_bloggers = len(BloggerDB.get_all_bloggers())
        scraped_count = BloggerDB.count_by_status("scraped")
        error_count = BloggerDB.count_by_status("error")

        col1, col2 = st.columns(2)
        with col1:
            st.metric("æ€»åšä¸»", total_bloggers)
            st.metric("å·²é‡‡é›†", scraped_count)
        with col2:
            st.metric("å¾…é‡‡é›†", pending_count)
            st.metric("å¤±è´¥", error_count)

    # Main area
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š åšä¸»æ’è¡Œ", "ğŸ”¥ çˆ†æ¬¾ç”»å»Š", "ğŸ“ˆ è¯¦ç»†åˆ†æ", "ğŸ—‚ï¸ åšä¸»ç®¡ç†"])

    with tab1:
        show_blogger_ranking()

    with tab2:
        show_outlier_gallery()

    with tab3:
        show_detailed_analysis()

    with tab4:
        show_blogger_management()


def show_blogger_ranking():
    """Display blogger ranking"""
    st.header("ğŸ“Š åšä¸»æ’è¡Œæ¦œ")

    # Get all scraped bloggers
    scraped_bloggers = [b for b in BloggerDB.get_all_bloggers() if b["status"] == "scraped"]

    if not scraped_bloggers:
        st.info("æš‚æ— å·²é‡‡é›†çš„åšä¸»æ•°æ®ã€‚è¯·å…ˆä½¿ç”¨ä¾§è¾¹æ çš„ã€Œæ•°æ®é‡‡é›†ã€åŠŸèƒ½ã€‚")
        return

    # Analyze all bloggers
    analyses = []
    for blogger in scraped_bloggers:
        analysis = analyze_blogger(blogger["user_id"])
        if "error" not in analysis:
            analyses.append(analysis)

    if not analyses:
        st.warning("åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®")
        return

    # Sort by outlier rate
    analyses.sort(key=lambda x: (x["outlier_rate"], x["avg_likes"]), reverse=True)

    # Create DataFrame with hyperlink
    df_data = []
    for analysis in analyses:
        blogger = analysis["blogger"]
        fans_count = blogger.get("current_fans", 0) or blogger.get("initial_fans", 0)
        url = f"https://www.xiaohongshu.com/user/profile/{blogger['user_id']}"
        df_data.append({
            "åšä¸»æ˜µç§°": blogger["nickname"],
            "ä¸»é¡µé“¾æ¥": url,  # Separate column for hyperlink
            "ç²‰ä¸æ•°": fans_count if fans_count > 0 else 0,
            "æ€»ç¬”è®°æ•°": analysis["total_notes"],
            "å¹³å‡ç‚¹èµ": int(analysis["avg_likes"]),
            "çˆ†æ¬¾æ•°é‡": analysis["outlier_count"],
            "çˆ†æ¬¾ç‡": f"{analysis['outlier_rate']:.1%}",
            "æ€»äº’åŠ¨é‡": analysis["total_engagement"],
            "æ¥æºå…³é”®è¯": blogger["source_keyword"] or "N/A",
            "user_id": blogger["user_id"]  # Hidden column for selection
        })

    df = pd.DataFrame(df_data)

    # Display metrics
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("åšä¸»æ€»æ•°", len(analyses))
    with col2:
        total_notes = sum(a["total_notes"] for a in analyses)
        st.metric("æ€»ç¬”è®°æ•°", total_notes)
    with col3:
        total_outliers = sum(a["outlier_count"] for a in analyses)
        st.metric("æ€»çˆ†æ¬¾æ•°", total_outliers)
    with col4:
        avg_outlier_rate = sum(a["outlier_rate"] for a in analyses) / len(analyses)
        st.metric("å¹³å‡çˆ†æ¬¾ç‡", f"{avg_outlier_rate:.1%}")

    st.markdown("---")

    # Display table
    st.subheader("åšä¸»åˆ—è¡¨ (æŒ‰çˆ†æ¬¾ç‡æ’åº)")

    # Show dataframe without user_id column
    display_df = df.drop(columns=["user_id"])
    st.dataframe(
        display_df,
        use_container_width=True,
        height=400
    )

    # Visualization: Bar chart
    st.markdown("---")
    st.subheader("ğŸ“Š å¯è§†åŒ–åˆ†æ")

    col1, col2 = st.columns(2)

    with col1:
        # Outlier rate chart
        fig1 = px.bar(
            df.head(10),
            x="åšä¸»æ˜µç§°",
            y="çˆ†æ¬¾ç‡",
            title="Top 10 åšä¸»çˆ†æ¬¾ç‡",
            color="çˆ†æ¬¾ç‡",
            color_continuous_scale="Reds"
        )
        fig1.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig1, use_container_width=True)

    with col2:
        # Average likes chart
        fig2 = px.bar(
            df.head(10),
            x="åšä¸»æ˜µç§°",
            y="å¹³å‡ç‚¹èµ",
            title="Top 10 åšä¸»å¹³å‡ç‚¹èµæ•°",
            color="å¹³å‡ç‚¹èµ",
            color_continuous_scale="Blues"
        )
        fig2.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig2, use_container_width=True)

    # Scatter plot: Notes vs Outlier Rate
    fig3 = px.scatter(
        df,
        x="æ€»ç¬”è®°æ•°",
        y="çˆ†æ¬¾ç‡",
        size="å¹³å‡ç‚¹èµ",
        color="çˆ†æ¬¾æ•°é‡",
        hover_data=["åšä¸»æ˜µç§°"],
        title="ç¬”è®°æ•°é‡ vs çˆ†æ¬¾ç‡ (æ°”æ³¡å¤§å°=å¹³å‡ç‚¹èµ)",
        color_continuous_scale="Viridis"
    )
    st.plotly_chart(fig3, use_container_width=True)


def show_outlier_gallery():
    """Display outlier notes gallery"""
    st.header("ğŸ”¥ çˆ†æ¬¾å†…å®¹ç”»å»Š")

    # Get all outlier notes
    outlier_notes = NoteDB.get_outlier_notes()

    if not outlier_notes:
        st.info("æš‚æ— çˆ†æ¬¾å†…å®¹ã€‚è¯·å…ˆä½¿ç”¨ä¾§è¾¹æ çš„ã€Œæ•°æ®åˆ†æã€åŠŸèƒ½è¯†åˆ«çˆ†æ¬¾ã€‚")
        return

    # Sort by likes
    outlier_notes.sort(key=lambda x: x["likes"], reverse=True)

    st.success(f"å…±å‘ç° {len(outlier_notes)} ç¯‡çˆ†æ¬¾å†…å®¹")

    # Filter options
    col1, col2 = st.columns([1, 3])
    with col1:
        min_likes_filter = st.number_input("æœ€ä½ç‚¹èµæ•°", value=0, step=1000)
    with col2:
        # Get unique users
        users = list(set(note["user_id"] for note in outlier_notes))
        user_names = {}
        for user_id in users:
            blogger = BloggerDB.get_blogger(user_id)
            if blogger:
                user_names[user_id] = blogger["nickname"]

        selected_user = st.selectbox(
            "ç­›é€‰åšä¸»",
            options=["å…¨éƒ¨"] + list(user_names.values())
        )

    # Apply filters
    filtered_notes = outlier_notes
    if min_likes_filter > 0:
        filtered_notes = [n for n in filtered_notes if n["likes"] >= min_likes_filter]

    if selected_user != "å…¨éƒ¨":
        selected_user_id = [uid for uid, name in user_names.items() if name == selected_user][0]
        filtered_notes = [n for n in filtered_notes if n["user_id"] == selected_user_id]

    st.markdown(f"**ç­›é€‰å: {len(filtered_notes)} ç¯‡**")
    st.markdown("---")

    # Display in grid
    cols_per_row = 3
    for i in range(0, len(filtered_notes), cols_per_row):
        cols = st.columns(cols_per_row)

        for j, col in enumerate(cols):
            idx = i + j
            if idx >= len(filtered_notes):
                break

            note = filtered_notes[idx]
            blogger = BloggerDB.get_blogger(note["user_id"])
            blogger_name = blogger["nickname"] if blogger else "Unknown"

            with col:
                # Card container
                with st.container():
                    st.markdown(f"### {note['title'][:30]}...")

                    # Display image if available
                    if note["local_cover_path"]:
                        try:
                            st.image(note["local_cover_path"], use_container_width=True)
                        except:
                            st.info("å°é¢å›¾åŠ è½½å¤±è´¥")
                    elif note["cover_url"]:
                        st.info("å°é¢æœªä¸‹è½½")
                    else:
                        st.info("æ— å°é¢å›¾")

                    # Metrics
                    metric_col1, metric_col2, metric_col3 = st.columns(3)
                    with metric_col1:
                        st.metric("â¤ï¸ ç‚¹èµ", f"{note['likes']:,}")
                    with metric_col2:
                        st.metric("â­ æ”¶è—", f"{note['collects']:,}")
                    with metric_col3:
                        st.metric("ğŸ’¬ è¯„è®º", f"{note['comments']:,}")

                    # Author and type
                    st.caption(f"ğŸ‘¤ {blogger_name}")
                    st.caption(f"ğŸ“ {note['type']} | ğŸ• {note['create_time']}")

                    # Link
                    if note.get("note_url"):
                        st.link_button("æŸ¥çœ‹åŸæ–‡", note["note_url"], use_container_width=True)

                st.markdown("---")


def show_detailed_analysis():
    """Display detailed analysis for selected blogger"""
    st.header("ğŸ“ˆ åšä¸»è¯¦ç»†åˆ†æ")

    # Get all scraped bloggers
    scraped_bloggers = [b for b in BloggerDB.get_all_bloggers() if b["status"] == "scraped"]

    if not scraped_bloggers:
        st.info("æš‚æ— å·²é‡‡é›†çš„åšä¸»æ•°æ®ã€‚")
        return

    # Blogger selection
    blogger_names = {b["user_id"]: b["nickname"] for b in scraped_bloggers}
    selected_name = st.selectbox(
        "é€‰æ‹©åšä¸»",
        options=list(blogger_names.values())
    )

    # Find user_id
    selected_user_id = [uid for uid, name in blogger_names.items() if name == selected_name][0]

    # Analyze
    analysis = analyze_blogger(selected_user_id)

    if "error" in analysis:
        st.error(f"åˆ†æå¤±è´¥: {analysis['error']}")
        return

    blogger = analysis["blogger"]

    # Display header
    col1, col2, col3, col4 = st.columns([1, 3, 1.5, 1])
    with col1:
        if blogger["avatar_url"]:
            st.image(blogger["avatar_url"], width=150)
        else:
            st.info("æ— å¤´åƒ")
    with col2:
        st.subheader(blogger['nickname'])
        # æ·»åŠ åšä¸»ä¸»é¡µé“¾æ¥æŒ‰é’®
        url = f"https://www.xiaohongshu.com/user/profile/{blogger['user_id']}"
        st.caption(f"User ID: {blogger['user_id']}")
        st.caption(f"çŠ¶æ€: {blogger['status']} | æ¥æº: {blogger['source_keyword']}")
    with col3:
        st.markdown("###  ")  # Spacing
        st.link_button("ğŸ”— è®¿é—®ä¸»é¡µ", url, use_container_width=True)
    with col4:
        st.markdown("###  ")  # Spacing
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ•°æ®", key=f"reset_{selected_user_id}", type="secondary", use_container_width=True):
            st.session_state[f"show_confirm_reset_{selected_user_id}"] = True

    # Confirmation dialog for reset
    if st.session_state.get(f"show_confirm_reset_{selected_user_id}", False):
        with st.expander("âš ï¸ ç¡®è®¤æ¸…ç©ºæ•°æ®", expanded=True):
            st.warning(f"ç¡®è®¤è¦æ¸…ç©º **{blogger['nickname']}** çš„æ‰€æœ‰ç¬”è®°æ•°æ®å—ï¼Ÿ")
            st.info("åšä¸»çŠ¶æ€å°†é‡ç½®ä¸º pendingï¼Œæ‰€æœ‰ç¬”è®°å°†è¢«åˆ é™¤ã€‚æ­¤æ“ä½œä¸å¯æ¢å¤ï¼")

            col_a, col_b = st.columns(2)
            with col_a:
                if st.button("âœ… ç¡®è®¤æ¸…ç©º", key=f"confirm_yes_{selected_user_id}", type="primary", use_container_width=True):
                    success = BloggerDB.reset_blogger_status(selected_user_id)
                    if success:
                        st.success(f"âœ“ å·²æ¸…ç©º {blogger['nickname']} çš„æ‰€æœ‰ç¬”è®°æ•°æ®")
                        st.session_state[f"show_confirm_reset_{selected_user_id}"] = False
                        st.rerun()
                    else:
                        st.error("æ¸…ç©ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“")
            with col_b:
                if st.button("âŒ å–æ¶ˆ", key=f"confirm_no_{selected_user_id}", use_container_width=True):
                    st.session_state[f"show_confirm_reset_{selected_user_id}"] = False
                    st.rerun()

    st.markdown("---")

    # Metrics
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»ç¬”è®°æ•°", analysis["total_notes"])
    with col2:
        st.metric("å¹³å‡ç‚¹èµ", f"{analysis['avg_likes']:.0f}")
    with col3:
        st.metric("çˆ†æ¬¾æ•°é‡", analysis["outlier_count"])
    with col4:
        st.metric("çˆ†æ¬¾ç‡", f"{analysis['outlier_rate']:.1%}")

    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        fans_count = blogger.get("current_fans", 0) or blogger.get("initial_fans", 0)
        st.metric("ç²‰ä¸æ•°", f"{fans_count:,}" if fans_count > 0 else "æœªé‡‡é›†")
    with col2:
        st.metric("æ€»ç‚¹èµ", f"{analysis['total_likes']:,}")
    with col3:
        st.metric("æ€»æ”¶è—", f"{analysis['total_collects']:,}")
    with col4:
        st.metric("æ€»è¯„è®º", f"{analysis['total_comments']:,}")
    with col5:
        st.metric("å¹³å‡äº’åŠ¨", f"{analysis['avg_engagement']:.0f}")

    st.markdown("---")

    # Content distribution
    st.subheader("ğŸ“Š å†…å®¹åˆ†å¸ƒ")
    col1, col2 = st.columns(2)

    with col1:
        # Pie chart: Content type
        fig_pie = go.Figure(data=[go.Pie(
            labels=["å›¾æ–‡", "è§†é¢‘"],
            values=[analysis["image_count"], analysis["video_count"]],
            hole=0.3
        )])
        fig_pie.update_layout(title="å†…å®¹ç±»å‹åˆ†å¸ƒ")
        st.plotly_chart(fig_pie, use_container_width=True)

    with col2:
        # Bar chart: Outlier vs Normal
        fig_bar = go.Figure(data=[go.Bar(
            x=["æ™®é€šå†…å®¹", "çˆ†æ¬¾å†…å®¹"],
            y=[analysis["total_notes"] - analysis["outlier_count"], analysis["outlier_count"]],
            marker_color=["lightblue", "red"]
        )])
        fig_bar.update_layout(title="å†…å®¹è´¨é‡åˆ†å¸ƒ", yaxis_title="æ•°é‡")
        st.plotly_chart(fig_bar, use_container_width=True)

    # Notes timeline
    st.subheader("ğŸ“ˆ ç¬”è®°æ•°æ®è¶‹åŠ¿")

    notes = NoteDB.get_notes_by_user(selected_user_id)
    if notes:
        df_notes = pd.DataFrame(notes)

        # Line chart: Likes over time
        fig_line = px.line(
            df_notes,
            x="create_time",
            y="likes",
            title="ç‚¹èµæ•°æ—¶é—´è¶‹åŠ¿",
            markers=True
        )
        fig_line.update_traces(line_color="red")
        st.plotly_chart(fig_line, use_container_width=True)

    # AI Report
    st.markdown("---")
    st.subheader("ğŸ¤– AI æ´å¯ŸæŠ¥å‘Š")

    # Import report functions
    from red_lens.analyzer import report_exists, load_report_from_file, delete_report_file, generate_ai_report
    import config

    # Check if report exists
    has_report = report_exists(selected_user_id)

    # Configuration controls
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        use_real_api = st.checkbox(
            "ä½¿ç”¨çœŸå® Deepseek API",
            value=config.ENABLE_REAL_AI,
            help="éœ€è¦é…ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡"
        )
    with col2:
        # Show report status
        if has_report:
            st.info("âœ“ å·²æœ‰æŠ¥å‘Š")
        else:
            st.caption("æ— æŠ¥å‘Š")
    with col3:
        if has_report and st.button("ğŸ—‘ï¸ åˆ é™¤æŠ¥å‘Š", help="åˆ é™¤å½“å‰åšä¸»çš„AIæŠ¥å‘Š"):
            if delete_report_file(selected_user_id):
                st.success("æŠ¥å‘Šå·²åˆ é™¤")
                st.rerun()

    # Display existing report if available
    if has_report:
        existing_report = load_report_from_file(selected_user_id)
        if existing_report:
            st.markdown(existing_report)
            st.markdown("---")

    # Generate/Regenerate button
    col_btn1, col_btn2 = st.columns([1, 3])
    with col_btn1:
        if has_report:
            generate_btn = st.button("ğŸ”„ é‡æ–°ç”ŸæˆæŠ¥å‘Š", type="secondary", use_container_width=True)
        else:
            generate_btn = st.button("âœ¨ ç”Ÿæˆ AI æŠ¥å‘Š", type="primary", use_container_width=True)
    with col_btn2:
        if use_real_api:
            st.caption("ğŸ’¡ ä½¿ç”¨çœŸå® API ç”ŸæˆæŠ¥å‘Š")
        else:
            st.caption("ğŸ’¡ ä½¿ç”¨ Mock æŠ¥å‘Šï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰")

    if generate_btn:
        use_mock = not use_real_api
        force_regenerate = has_report  # If report exists, force regenerate
        spinner_text = "AI æ­£åœ¨åˆ†æ..." if use_real_api else "ç”Ÿæˆæ¨¡æ‹ŸæŠ¥å‘Š..."
        with st.spinner(spinner_text):
            try:
                report = generate_ai_report(selected_user_id, use_mock=use_mock, force_regenerate=force_regenerate)
                if report.startswith("Error:"):
                    st.error(report)
                else:
                    st.success("âœ“ æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                    st.rerun()  # Reload to display the new report
            except Exception as e:
                st.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}")

    # Top notes
    st.markdown("---")
    st.subheader("ğŸ” çƒ­é—¨ç¬”è®° Top 10")

    if notes:
        top_notes = sorted(notes, key=lambda x: x["likes"], reverse=True)[:10]

        for idx, note in enumerate(top_notes, 1):
            with st.container():
                # Create a card-like display for each note
                col1, col2, col3, col4, col5 = st.columns([3, 1, 1, 1, 1])

                with col1:
                    outlier_badge = "ğŸ”¥ " if note["is_outlier"] else ""
                    st.markdown(f"**{idx}. {outlier_badge}{note['title'][:50]}...**")
                    st.caption(f"ğŸ“ {note['type']} | ğŸ• {note['create_time']}")

                with col2:
                    st.metric("â¤ï¸", f"{note['likes']:,}")

                with col3:
                    st.metric("â­", f"{note['collects']:,}")

                with col4:
                    st.metric("ğŸ’¬", f"{note['comments']:,}")

                with col5:
                    if note.get("note_url"):
                        st.link_button("æŸ¥çœ‹", note["note_url"], use_container_width=True)
                    else:
                        st.caption("æ— é“¾æ¥")

                st.markdown("---")


def show_blogger_management():
    """Display blogger management page with filtering and batch operations"""
    st.header("ğŸ—‚ï¸ åšä¸»ç®¡ç†")

    # Get all bloggers
    all_bloggers = BloggerDB.get_all_bloggers()

    if not all_bloggers:
        st.info("æš‚æ— åšä¸»æ•°æ®")
        return

    st.success(f"æ•°æ®åº“ä¸­å…±æœ‰ {len(all_bloggers)} ä½åšä¸»")

    # Filters
    st.subheader("ğŸ” ç­›é€‰æ¡ä»¶")
    col1, col2, col3 = st.columns(3)

    with col1:
        # Status filter
        status_options = ["å…¨éƒ¨çŠ¶æ€", "pending", "scraped", "error"]
        selected_status = st.selectbox("æŒ‰çŠ¶æ€ç­›é€‰", status_options)

    with col2:
        # Keyword filter
        # Get unique keywords
        keywords = set()
        for blogger in all_bloggers:
            if blogger.get("source_keyword"):
                keywords.add(blogger["source_keyword"])

        keyword_options = ["å…¨éƒ¨å…³é”®è¯"] + sorted(list(keywords))
        selected_keyword = st.selectbox("æŒ‰æ¥æºå…³é”®è¯ç­›é€‰", keyword_options)

    with col3:
        # Fans filter
        enable_fans_filter = st.checkbox("å¯ç”¨ç²‰ä¸æ•°ç­›é€‰", value=False)
        if enable_fans_filter:
            min_fans_filter = st.number_input(
                "æœ€ä½ç²‰ä¸æ•°",
                min_value=0,
                max_value=1000000,
                value=1000,
                step=1000,
                help="åªæ˜¾ç¤ºç²‰ä¸æ•°å¤§äºç­‰äºæ­¤å€¼çš„åšä¸»"
            )
        else:
            min_fans_filter = 0

    # Apply filters
    filtered_bloggers = all_bloggers

    if selected_status != "å…¨éƒ¨çŠ¶æ€":
        filtered_bloggers = [b for b in filtered_bloggers if b["status"] == selected_status]

    if selected_keyword != "å…¨éƒ¨å…³é”®è¯":
        filtered_bloggers = [b for b in filtered_bloggers if b.get("source_keyword") == selected_keyword]

    if enable_fans_filter and min_fans_filter > 0:
        filtered_bloggers = [
            b for b in filtered_bloggers
            if (b.get("current_fans", 0) or b.get("initial_fans", 0)) >= min_fans_filter
        ]

    st.info(f"ç­›é€‰å: {len(filtered_bloggers)} ä½åšä¸»")

    st.markdown("---")

    # Blogger list with checkboxes
    st.subheader("ğŸ“‹ åšä¸»åˆ—è¡¨")

    if not filtered_bloggers:
        st.warning("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„åšä¸»")
        return

    # Select all checkbox
    select_all = st.checkbox("å…¨é€‰", key="select_all_bloggers")

    # Initialize session state for selections
    if "selected_bloggers" not in st.session_state:
        st.session_state.selected_bloggers = set()

    if select_all:
        st.session_state.selected_bloggers = set(b["user_id"] for b in filtered_bloggers)
    elif not select_all and len(st.session_state.selected_bloggers) == len(filtered_bloggers):
        # If all were selected and user unchecks "select all"
        st.session_state.selected_bloggers = set()

    # Display bloggers in a scrollable container
    st.markdown("**é€‰æ‹©è¦åˆ é™¤çš„åšä¸»ï¼š**")

    # Create a table-like display with checkboxes
    for idx, blogger in enumerate(filtered_bloggers):
        col1, col2, col3, col4, col5, col6, col7 = st.columns([0.5, 2, 1.5, 1, 1, 1, 1.2])

        with col1:
            is_selected = blogger["user_id"] in st.session_state.selected_bloggers
            if st.checkbox("é€‰æ‹©", value=is_selected, key=f"cb_{blogger['user_id']}_{idx}", label_visibility="hidden"):
                st.session_state.selected_bloggers.add(blogger["user_id"])
            else:
                st.session_state.selected_bloggers.discard(blogger["user_id"])

        with col2:
            # åšä¸»åç§°ä½œä¸ºè¶…é“¾æ¥ï¼Œç‚¹å‡»è·³è½¬åˆ°å°çº¢ä¹¦ä¸»é¡µ
            url = f"https://www.xiaohongshu.com/user/profile/{blogger['user_id']}"
            st.markdown(f"[{blogger['nickname']}]({url})")

        with col3:
            st.caption(f"å…³é”®è¯: {blogger.get('source_keyword', 'N/A')}")

        with col4:
            status_emoji = {"pending": "â³", "scraped": "âœ…", "error": "âŒ"}
            st.caption(f"{status_emoji.get(blogger['status'], 'â“')} {blogger['status']}")

        with col5:
            fans = blogger.get("current_fans", 0) or blogger.get("initial_fans", 0)
            if fans > 0:
                st.caption(f"ğŸ‘¥ {fans:,}")
            else:
                st.caption("ğŸ‘¥ æœªé‡‡é›†")

        with col6:
            # Get note count
            note_count = NoteDB.count_notes_by_user(blogger["user_id"])
            st.caption(f"ğŸ“ {note_count} ç¬”è®°")

        with col7:
            # Show scrape progress
            progress = BloggerDB.get_scrape_progress(blogger["user_id"])
            if progress['notes_collected'] > 0 or progress['scrape_status'] != 'not_started':
                progress_pct = min(progress['notes_collected'] / max(progress['notes_target'], 1), 1.0)
                st.progress(progress_pct, text=f"{progress['notes_collected']}/{progress['notes_target']}")
            else:
                st.caption("æœªå¼€å§‹")

    st.markdown("---")

    # Batch operations
    st.subheader("âš™ï¸ æ‰¹é‡æ“ä½œ")

    selected_count = len(st.session_state.selected_bloggers)
    st.info(f"å·²é€‰æ‹© {selected_count} ä½åšä¸»")

    if selected_count == 0:
        st.warning("è¯·å…ˆé€‰æ‹©è¦æ“ä½œçš„åšä¸»")
    else:
        col1, col2 = st.columns(2)

        with col1:
            if st.button("ğŸ—‘ï¸ æ‰¹é‡åˆ é™¤é€‰ä¸­åšä¸»", type="primary", use_container_width=True):
                st.session_state.show_batch_delete_confirm = True

        with col2:
            if st.button("ğŸ”„ æ‰¹é‡é‡ç½®ä¸º pending", use_container_width=True):
                st.session_state.show_batch_reset_confirm = True

    # Batch delete confirmation
    if st.session_state.get("show_batch_delete_confirm", False):
        with st.expander("âš ï¸ ç¡®è®¤æ‰¹é‡åˆ é™¤", expanded=True):
            st.error(f"ç¡®è®¤è¦åˆ é™¤é€‰ä¸­çš„ **{selected_count}** ä½åšä¸»åŠå…¶æ‰€æœ‰ç¬”è®°å—ï¼Ÿ")
            st.warning("æ­¤æ“ä½œå°†æ°¸ä¹…åˆ é™¤åšä¸»ä¿¡æ¯å’Œæ‰€æœ‰ç¬”è®°ï¼Œä¸å¯æ¢å¤ï¼")

            # Show list of bloggers to be deleted
            st.markdown("**å°†è¦åˆ é™¤çš„åšä¸»ï¼š**")
            for user_id in list(st.session_state.selected_bloggers)[:10]:  # Show first 10
                blogger = next((b for b in filtered_bloggers if b["user_id"] == user_id), None)
                if blogger:
                    st.markdown(f"- {blogger['nickname']} ({blogger.get('source_keyword', 'N/A')})")
            if selected_count > 10:
                st.markdown(f"... ä»¥åŠå…¶ä»– {selected_count - 10} ä½åšä¸»")

            col_a, col_b = st.columns(2)
            with col_a:
                if st.button("âœ… ç¡®è®¤åˆ é™¤", key="confirm_batch_delete", type="primary", use_container_width=True):
                    deleted_count = 0
                    total_notes_deleted = 0

                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    for i, user_id in enumerate(st.session_state.selected_bloggers):
                        status_text.text(f"æ­£åœ¨åˆ é™¤... ({i+1}/{selected_count})")
                        progress_bar.progress((i + 1) / selected_count)

                        # Count notes before deletion
                        note_count = NoteDB.count_notes_by_user(user_id)

                        # Delete blogger and notes
                        if BloggerDB.delete_blogger(user_id):
                            deleted_count += 1
                            total_notes_deleted += note_count

                    st.success(f"âœ“ å·²åˆ é™¤ {deleted_count} ä½åšä¸»å’Œ {total_notes_deleted} æ¡ç¬”è®°")
                    st.session_state.selected_bloggers = set()
                    st.session_state.show_batch_delete_confirm = False
                    st.rerun()

            with col_b:
                if st.button("âŒ å–æ¶ˆ", key="cancel_batch_delete", use_container_width=True):
                    st.session_state.show_batch_delete_confirm = False
                    st.rerun()

    # Batch reset confirmation
    if st.session_state.get("show_batch_reset_confirm", False):
        with st.expander("âš ï¸ ç¡®è®¤æ‰¹é‡é‡ç½®", expanded=True):
            st.warning(f"ç¡®è®¤è¦å°†é€‰ä¸­çš„ **{selected_count}** ä½åšä¸»é‡ç½®ä¸º pending çŠ¶æ€å—ï¼Ÿ")
            st.info("æ­¤æ“ä½œå°†åˆ é™¤è¿™äº›åšä¸»çš„æ‰€æœ‰ç¬”è®°ï¼Œä½†ä¿ç•™åšä¸»ä¿¡æ¯ã€‚")

            col_a, col_b = st.columns(2)
            with col_a:
                if st.button("âœ… ç¡®è®¤é‡ç½®", key="confirm_batch_reset", type="primary", use_container_width=True):
                    reset_count = 0
                    total_notes_deleted = 0

                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    for i, user_id in enumerate(st.session_state.selected_bloggers):
                        status_text.text(f"æ­£åœ¨é‡ç½®... ({i+1}/{selected_count})")
                        progress_bar.progress((i + 1) / selected_count)

                        # Count notes before deletion
                        note_count = NoteDB.count_notes_by_user(user_id)

                        # Reset blogger status
                        if BloggerDB.reset_blogger_status(user_id):
                            reset_count += 1
                            total_notes_deleted += note_count

                    st.success(f"âœ“ å·²é‡ç½® {reset_count} ä½åšä¸»ï¼Œåˆ é™¤ {total_notes_deleted} æ¡ç¬”è®°")
                    st.session_state.selected_bloggers = set()
                    st.session_state.show_batch_reset_confirm = False
                    st.rerun()

            with col_b:
                if st.button("âŒ å–æ¶ˆ", key="cancel_batch_reset", use_container_width=True):
                    st.session_state.show_batch_reset_confirm = False
                    st.rerun()


if __name__ == "__main__":
    main()
